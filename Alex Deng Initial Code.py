# -*- coding: utf-8 -*-
"""RDKit Tutorial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/161DU3fzKFxAfTfXAt73AQ3VSRrlIM8QL
"""

# Install RDKit. Takes 2-3 minutes
!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
!chmod +x Miniconda3-latest-Linux-x86_64.sh
!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local
!time conda install -q -y -c conda-forge rdkit

import sys
sys.path.append('/usr/local/lib/python3.7/site-packages/')

from rdkit import Chem
from rdkit.Chem import Draw
from rdkit.Chem.Draw import IPythonConsole
from rdkit.Chem import Descriptors
from rdkit.Chem import AllChem
from rdkit import DataStructs
import numpy as np

def getTani (fp, fp2):
  return (DataStructs.TanimotoSimilarity(fp,fp2))
#generate numpy array with all fingerprints

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Comment this if the data visualisations doesn't work on your side
# %matplotlib inline

plt.style.use('bmh')

df = pd.read_csv('/content/drive/My Drive/TB Internship/MergedDataset.csv')
df

from google.colab import drive
drive.mount('/content/drive')

#df = df.loc[df['SMILES'] != 'No Match']

list_combo = []
list_pair = []
list_zscore= []
list_stem = []
list_Smiles = []
list_tani = []
list_l2fc = []
for c in df['stem']:
  list_stem.append(c)
for c in df['SMILES']:
  list_Smiles.append(c)
for c in df['log2_fold_change']:
  list_l2fc.append(c)

from math import sqrt
def euclid(l1, l2):
  return sqrt((l1-l2)**2)

df['SMILES'][1380] = "No Match"
df['SMILES'][1709] = "No Match"
df['SMILES'][2354] = "No Match"
df['SMILES'][2355] = "No Match"
list_mol = []

for c in df['SMILES']:
  if c == "No Match" or c is "nan" :
    list_mol.append("NONE")
  else:
    print(c)
    mol1 = Chem.MolFromSmiles(c)
    list_mol.append(mol1)

df['MOL'] = list_mol

list_finger = []
for c in df['MOL']:
  if c == "NONE" :
    list_finger.append("NONE")
  else:
    print(c)
    fp = AllChem.GetMorganFingerprintAsBitVect(c,2,nBits = 1024)
    list_finger.append(fp)

df['FingerPrints'] = list_finger

'''
list_combo = []
list_pair = []
list_stem = []
list_Smiles = []
list_tani = []
list_l2fc = []
list_l2dif = []
list_zscore = []
list_zdiff = []

for c in df['stem']:
  list_stem.append(c)
for c in df['SMILES']:
  list_Smiles.append(c)
for c in df['log2_fold_change']:
  list_l2fc.append(c)
for c in df['z_score']:
  list_zscore.append(c)
  
list_Smiles[1380] = "No Match"
list_Smiles[1709] = "No Match"
list_Smiles[2354] = "No Match"
list_Smiles[2355] = "No Match"

for i in range(0,3169):
  if list_Smiles[i] == "No Match" or list_Smiles[i] == "nan" :
    pass
  else:
    list_pair = [list_stem[i],list_stem[0]]
    list_combo.append(list_pair)
    list_l2dif.append(euclid(list_l2fc[i],list_l2fc[0]))
    list_tani.append(1-getTani(list_finger[i],list_finger[0]))
    list_zdiff.append(euclid(list_zscore[i],list_zscore[0]))
    
     '''

from scipy import stats
list_combo = []
list_pair = []
list_stem = []
list_Smiles = []
list_tani = []
list_l2fc = []
list_l2dif = []
list_zscore = []
list_zdiff = []
list_r =[]
list_comp = []

for c in df['stem']:
  list_stem.append(c)
for c in df['SMILES']:
  list_Smiles.append(c)
for c in df['log2_fold_change']:
  list_l2fc.append(c)
for c in df['z_score']:
  list_zscore.append(c)

for i in range(0,3168):
  if list_Smiles[i] == "No Match" or list_Smiles[i] == "nan":
    print(i)
  else:
    for j in range (i+1, 3169):
      if list_Smiles[j] == "No Match" or list_Smiles[j] == "nan" :
        pass
      else:
        list_pair = [list_stem[i],list_stem[j]]
        list_combo.append(list_pair)
        list_l2dif.append(euclid(list_l2fc[i],list_l2fc[j]))
        list_tani.append(1-getTani(list_finger[i],list_finger[j]))
        list_zdiff.append(euclid(list_zscore[i],list_zscore[j]))
  x = list_tani
  y = list_l2dif
  slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)
  list_r.append(r_value)
  list_comp.append(list_stem[i])

data = {'stem_pair': list_combo,
        '1-tanimoto': list_tani,
        'zdiff': list_zdiff,
        'l2diff': list_l2dif}
dfnew = pd.DataFrame (data, columns = ['stem_pair','1-tanimoto','zdiff', 'l2diff'])
'''
dfnew['stem_pair'] = list_combo
dfnew['1-tanimoto'] = list_tani
dfnew['zdif'] = list_zdiff
dfnew['l2dif'] = list_l2dif
'''

dfnew

dfnew.to_csv(r'/content/drive/My Drive/TB Internship/Simplified_Tani_indfull.csv', index = False)

df.to_csv(r'/content/drive/My Drive/TB Internship/MergedNew.csv', index = False)

#data = pd.read_csv("/content/drive/My Drive/TB Internship/Simplified_Tani_ind2.csv")
data = dfnew
data.plot(kind='scatter', x='1-tanimoto', y='zdiff')
#separate close and far and make separate graphs and correlations
#process distances with sklearn compile
#quantile transform (remaps everything in a nonlinear way)
#quartile
#Get r/r^2
#sidepy distance to do pairwise distance
#generate numpy array with all fingerprints so that it doesnt need to generate mol for each smile in loop
#Find aggregate statistic for each strain to determine which ones are worth tackling in the acutal model.

'''
x = dfnew['zdiff']
y = dfnew['1-tanimoto']
#use pearson r from scipy
#r^2 scikitlearn
correlation_matrix = np.corrcoef(x, y)
correlation_xy = correlation_matrix[0,1]
r_squared = correlation_xy**2
print(correlation_matrix)
print(correlation_xy)
print(r_squared)
'''

'''
NOTES
